{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+u/5e1Xy2sCsAkxVooDQL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaksta1/Uczenie_Maszynowe_2025/blob/main/Jakub_Kownacki_praca_domowa_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------\n",
        "# 1. Importowanie bibliotek\n",
        "---------------------------------"
      ],
      "metadata": {
        "id": "ZqmEufEwLMCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "plt.rcParams['animation.embed_limit'] = 50 #zwiƒôkszenie limitu pamiƒôci do stworzenia animacji\n",
        "# Ustawienie ziarna dla powtarzalno≈õci\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "0S6eQNomJm7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------\n",
        "#2. Ustawienia parametr√≥w\n",
        "-------------------------------------------"
      ],
      "metadata": {
        "id": "ECALgDkOLbfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametry elipsy\n",
        "focus1 = torch.tensor([-2.0, 0.0])  # Pierwsze ognisko\n",
        "focus2 = torch.tensor([2.0, 0.0])   # Drugie ognisko\n",
        "constant_sum = 6.0                  # Sta≈Ça suma odleg≈Ço≈õci\n",
        "\n",
        "# Inicjalizacja losowych punkt√≥w\n",
        "num_points = 100\n",
        "points = torch.rand((num_points, 2)) * 10 - 5  # Rozk≈Çad jednostajny w [-5, 5]\n",
        "points.requires_grad = True"
      ],
      "metadata": {
        "id": "rV_KIIy5Lw7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------\n",
        "#3. Funkcje pomocnicze\n",
        "------------------------------------------------"
      ],
      "metadata": {
        "id": "6J-EKi9tLzJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja obliczajƒÖca odleg≈Ço≈õci\n",
        "def compute_distances(points, focus1, focus2):\n",
        "    dist1 = torch.norm(points - focus1, dim=1)\n",
        "    dist2 = torch.norm(points - focus2, dim=1)\n",
        "    return dist1, dist2\n",
        "\n",
        "def l0_approx_sigmoid(epsilon, delta, alpha=50):\n",
        "    \"\"\"\n",
        "    Aproksymacja normy L0 za pomocƒÖ funkcji sigmoidalnej.\n",
        "    Parametry:\n",
        "        epsilon: tensor warto≈õci b≈Çƒôd√≥w\n",
        "        delta: pr√≥g, poni≈ºej kt√≥rego b≈Çƒôdy sƒÖ uznawane za zerowe\n",
        "        alpha: parametr kontrolujƒÖcy nachylenie funkcji sigmoidalnej, wiƒôksze warto≈õci alpha sprawiajƒÖ,\n",
        "        ≈ºe aproksymacja staje siƒô bardziej \"skokowa\", zbli≈ºajƒÖc siƒô do idealnej normy L0\n",
        "        r√≥≈ºniczkowalno≈õƒá: funkcja sigmoidalna jest r√≥≈ºniczkowalna, zatem mo≈ºemy jej u≈ºyƒá do\n",
        "        obliczenia gradientu funkcji straty.\n",
        "    Zwraca:\n",
        "        aproksymowanƒÖ warto≈õƒá normy L0\n",
        "    \"\"\"\n",
        "    return 1 / (1 + torch.exp(-alpha * (torch.abs(epsilon) - delta)))\n",
        "\n",
        "# Funkcja treningowa z zapisem trajektorii i straty\n",
        "def train_with_animation(loss_type, num_epochs=1000, lr=0.1):\n",
        "    points = torch.rand((num_points, 2)) * 10 - 5\n",
        "    points.requires_grad = True\n",
        "    optimizer = torch.optim.Adam([points], lr=lr)\n",
        "    trajectories = []  # Lista do przechowywania po≈Ço≈ºenia punkt√≥w w ka≈ºdej epoce\n",
        "    loss_history = []  # Lista do przechowywania warto≈õci straty w ka≈ºdej epoce\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        dist1, dist2 = compute_distances(points, focus1, focus2)\n",
        "        epsilon = dist1 + dist2 - constant_sum\n",
        "\n",
        "        if loss_type == \"l2\":\n",
        "            loss = torch.mean(epsilon ** 2)\n",
        "        elif loss_type == \"l1\":\n",
        "            loss = torch.mean(torch.abs(epsilon))\n",
        "        elif loss_type == \"linf\":\n",
        "            loss = torch.max(torch.abs(epsilon))\n",
        "        elif loss_type == \"l0\":\n",
        "            delta = 0.01\n",
        "            loss = torch.mean(l0_approx_sigmoid(epsilon, delta))  # U≈ºyj aproksymacji sigmoidalnej\n",
        "        else:\n",
        "            raise ValueError(\"Nieprawid≈Çowy typ straty\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zapisz aktualne po≈Ço≈ºenia punkt√≥w i stratƒô\n",
        "        trajectories.append(points.detach().clone().numpy())\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    return trajectories, loss_history"
      ],
      "metadata": {
        "id": "-dyRgQ02MFNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------\n",
        "#4. Trening dla straty L1\n",
        "---------------------------------------------"
      ],
      "metadata": {
        "id": "mYMnk26mM3mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uruchom trening dla straty l1\n",
        "trajectories_l1, loss_history_l1 = train_with_animation(\"l1\", num_epochs=300)\n",
        "\n",
        "# Tworzenie animacji z dwoma subplotami\n",
        "fig_l1, (ax1_l1, ax2_l1) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Punkty\n",
        "ax1_l1.set_xlim(-6, 6)\n",
        "ax1_l1.set_ylim(-6, 6)\n",
        "scatter_l1 = ax1_l1.scatter([], [], label='Punkty')\n",
        "ax1_l1.scatter([focus1[0], focus2[0]], [focus1[1], focus2[1]], color='red', marker='x', s=100, label='Ogniska')\n",
        "ax1_l1.legend()\n",
        "ax1_l1.grid()\n",
        "ax1_l1.set_title('Ruch punkt√≥w dla straty L1')\n",
        "\n",
        "# Subplot 2: Wykres straty\n",
        "ax2_l1.set_xlim(0, len(loss_history_l1))\n",
        "ax2_l1.set_ylim(0, max(loss_history_l1) * 1.1)\n",
        "line_l1, = ax2_l1.plot([], [], color='blue')\n",
        "ax2_l1.set_xlabel('Epoka')\n",
        "ax2_l1.set_ylabel('Strata')\n",
        "ax2_l1.set_title('Przebieg funkcji straty L1')\n",
        "ax2_l1.grid()\n",
        "\n",
        "def update_l1(frame):\n",
        "    # Aktualizacja po≈Ço≈ºenia punkt√≥w\n",
        "    scatter_l1.set_offsets(trajectories_l1[frame])\n",
        "\n",
        "    # Aktualizacja wykresu straty\n",
        "    line_l1.set_data(range(frame + 1), loss_history_l1[:frame + 1])\n",
        "\n",
        "    return scatter_l1, line_l1\n",
        "\n",
        "ani_l1 = animation.FuncAnimation(fig_l1, update_l1, frames=len(trajectories_l1), interval=50, blit=True)\n",
        "print(\"Ostatnia warto≈õƒá funkcji b≈Çƒôdu L1:\", loss_history_l1[-1])\n",
        "\n",
        "# Wy≈õwietlenie animacji w notebooku\n",
        "HTML(ani_l1.to_jshtml())\n"
      ],
      "metadata": {
        "id": "p2WOMuFPDH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dlaczego strata $L^1$ nie zbiega do zera nawet po narysowaniu elipsy?\n",
        "\n",
        "Norma L1 to $ùêø_{\\text{ellipse}}^{(1)}=\\frac{1}{ùëÅ}‚àë_{ùëñ=1}^ùëÅ‚à£ùúñ_ùëñ‚à£$, czyli ≈õrednia warto≈õƒá bezwzglƒôdna b≈Çƒôd√≥w.\\\n",
        "Powodem nie zbiegania straty L1 do 0 jest to, ≈ºe w przeciwie≈Ñstwie do normy L2 (b≈Çƒôdu kwadratowego), kt√≥ra silnie karze nawet ma≈Çe odchylenia (gradient ro≈õnie z b≈Çƒôdem), norma L1 ma sta≈Çy gradient (¬±1 w zale≈ºno≈õci od znaku $ùúñ_ùëñ $‚Äã\n",
        " ). To sprawia, ≈ºe ma≈Çe b≈Çƒôdy sƒÖ s≈Çabo penalizowane, wiƒôc punkty mogƒÖ byƒá blisko elipsy, ale nie dok≈Çadnie na niej. W zwiƒÖzku z tym optymalizacja mo≈ºe oscylowaƒá lub zwolniƒá, gdy b≈Çƒôdy sƒÖ ma≈Çe, co prowadzi do ustabilizowania warto≈õci straty na poziomie powy≈ºej zera.\\\n",
        "**Wynik**: Strata nie zbiega do zera, bo L1 nie wymusza precyzyjnego dopasowania punkt√≥w do warunku.\\\n",
        "Wszystkie te wnioski sƒÖ zgodne z powy≈ºszƒÖ animacjƒÖ, na kt√≥rej widaƒá, ≈ºe dla odpowiednio du≈ºej liczby iteracji b≈ÇƒÖd utrzymuje siƒô na sta≈Çej warto≈õci oko≈Ço 0.02 pomimo tego, ≈ºe uzyskali≈õmy elipsƒô."
      ],
      "metadata": {
        "id": "h5jJqWVhM-W0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------\n",
        "#5. Trening dla straty $L^{‚àû}$\n",
        "-----------------------------------------------"
      ],
      "metadata": {
        "id": "_S9Er7tvPp7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uruchom trening dla straty L_inf\n",
        "trajectories_linf, loss_history_linf = train_with_animation(\"linf\", num_epochs=800)\n",
        "\n",
        "# Tworzenie animacji z dwoma subplotami\n",
        "fig_linf, (ax1_linf, ax2_linf) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Punkty\n",
        "ax1_linf.set_xlim(-6, 6)\n",
        "ax1_linf.set_ylim(-6, 6)\n",
        "scatter_linf = ax1_linf.scatter([], [], label='Punkty')\n",
        "ax1_linf.scatter([focus1[0], focus2[0]], [focus1[1], focus2[1]], color='red', marker='x', s=100, label='Ogniska')\n",
        "ax1_linf.legend()\n",
        "ax1_linf.grid()\n",
        "ax1_linf.set_title('Ruch punkt√≥w dla straty L_inf')\n",
        "\n",
        "# Subplot 2: Wykres straty\n",
        "ax2_linf.set_xlim(0, len(loss_history_linf))\n",
        "ax2_linf.set_ylim(0, max(loss_history_linf) * 1.1)\n",
        "line_linf, = ax2_linf.plot([], [], color='blue')\n",
        "ax2_linf.set_xlabel('Epoka')\n",
        "ax2_linf.set_ylabel('Strata')\n",
        "ax2_linf.set_title('Przebieg funkcji straty L_inf')\n",
        "ax2_linf.grid()\n",
        "\n",
        "def update_linf(frame):\n",
        "    # Aktualizacja po≈Ço≈ºenia punkt√≥w\n",
        "    scatter_linf.set_offsets(trajectories_linf[frame])\n",
        "\n",
        "    # Aktualizacja wykresu straty\n",
        "    line_linf.set_data(range(frame + 1), loss_history_linf[:frame + 1])\n",
        "\n",
        "    return scatter_linf, line_linf\n",
        "\n",
        "ani_linf = animation.FuncAnimation(fig_linf, update_linf, frames=len(trajectories_linf), interval=50, blit=True)\n",
        "print(\"Ostatnia warto≈õƒá funkcji b≈Çƒôdu L_inf:\", loss_history_linf[-1])\n",
        "\n",
        "# Wy≈õwietlenie animacji w notebooku\n",
        "HTML(ani_linf.to_jshtml())\n"
      ],
      "metadata": {
        "id": "qv00aaZsELtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dlaczego trening trwa d≈Çugo i strata nie zbiega do zera?\n",
        "\n",
        "Norma $L_{\\text{inf}}$ to maksymalny b≈ÇƒÖd w≈õr√≥d wszystkich punkt√≥w.\\\n",
        "Zatem optymalizacja koncentruje siƒô wy≈ÇƒÖcznie na punkcie z najwiƒôkszym b≈Çƒôdem, ignorujƒÖc pozosta≈Çe, dop√≥ki ten b≈ÇƒÖd nie zostanie zredukowany. To powoduje powolny postƒôp, bo tylko jeden punkt (lub kilka) jest poprawianych w ka≈ºdej iteracji. Istnieje te≈º ryzyko prze≈ÇƒÖczanie siƒô miƒôdzy punktami o najwiƒôkszym b≈Çƒôdzie, co prowadzi do nieefektywnego ruchu w przestrzeni, a brak r√≥wnoczesnej poprawy wszystkich punkt√≥w utrudnia pe≈Çne dopasowanie do elipsy.\\\n",
        "**Wynik**: Trening jest wolny i czƒôsto nie zbiega do zera, bo strategia \"najgorszego przypadku\" nie optymalizuje globalnie uk≈Çadu punkt√≥w.\\\n",
        "Na powy≈ºszej animacji ruchu punkt√≥w widaƒá, ≈ºe na poczƒÖtku udaje siƒô uzyskaƒá \"zarys\" elipsy, jednak w pewnym momencie algorytmowi ciƒô≈ºko wybraƒá punkty i kierunek ich przesuniƒôcia taki, aby zmniejszyƒá b≈ÇƒÖd, co widaƒá na animacji przebiegu funkcji straty."
      ],
      "metadata": {
        "id": "Q82YIViMU1XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------\n",
        "#6. Trening dla straty L0\n",
        "----------------------------------------------"
      ],
      "metadata": {
        "id": "uyNTbx7Oakcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uruchom trening dla straty l0\n",
        "trajectories_l0, loss_history_l0 = train_with_animation(\"l0\", num_epochs=300)\n",
        "\n",
        "# Tworzenie animacji z dwoma subplotami\n",
        "fig_l0, (ax1_l0, ax2_l0) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Punkty\n",
        "ax1_l0.set_xlim(-6, 6)\n",
        "ax1_l0.set_ylim(-6, 6)\n",
        "scatter_l0 = ax1_l0.scatter([], [], label='Punkty')\n",
        "ax1_l0.scatter([focus1[0], focus2[0]], [focus1[1], focus2[1]], color='red', marker='x', s=100, label='Ogniska')\n",
        "ax1_l0.legend()\n",
        "ax1_l0.grid()\n",
        "ax1_l0.set_title('Ruch punkt√≥w dla straty L0')\n",
        "\n",
        "# Subplot 2: Wykres straty\n",
        "ax2_l0.set_xlim(0, len(loss_history_l0))\n",
        "ax2_l0.set_ylim(0, max(loss_history_l0) * 1.1 if loss_history_l0 else 1)\n",
        "line_l0, = ax2_l0.plot([], [], color='blue')\n",
        "ax2_l0.set_xlabel('Epoka')\n",
        "ax2_l0.set_ylabel('Strata')\n",
        "ax2_l0.set_title('Przebieg funkcji straty L0')\n",
        "ax2_l0.grid()\n",
        "\n",
        "def update_l0(frame):\n",
        "    # Aktualizacja po≈Ço≈ºenia punkt√≥w\n",
        "    scatter_l0.set_offsets(trajectories_l0[frame])\n",
        "\n",
        "    # Aktualizacja wykresu straty\n",
        "    line_l0.set_data(range(frame + 1), loss_history_l0[:frame + 1])\n",
        "\n",
        "    return scatter_l0, line_l0\n",
        "\n",
        "ani_l0 = animation.FuncAnimation(fig_l0, update_l0, frames=len(trajectories_l0), interval=50, blit=True)\n",
        "print(\"Ostatnia warto≈õƒá funkcji b≈Çƒôdu L0:\", loss_history_l0[-1])\n",
        "\n",
        "# Wy≈õwietlenie animacji w notebooku\n",
        "HTML(ani_l0.to_jshtml())"
      ],
      "metadata": {
        "id": "e8ISMSVfPJHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dlaczego trening nie postƒôpuje?\n",
        "Norma L0 jest zdefiniowana jako $L^{(0)}_{\\text{ellipse}}=\\frac{1}{N}‚àë_{i=1}^N\\mathbb{1}(œµ_i\\neq1)$.\\\n",
        "Norma L0 zlicza wiƒôc stosunek liczby punkt√≥w, dla kt√≥rych b≈ÇƒÖd $ùúñ_ùëñ$ nie jest r√≥wny zero do liczby wszystkich punkt√≥w.\\\n",
        "Trening nie postƒôpuje, poniewa≈º indykator $\\mathbb{1}_(œµ_i\\neq1)$ jest funkcjƒÖ skokowƒÖ ‚Äì zmienia siƒô z 0 na 1 w spos√≥b dyskretny, nie jest to zatem funkcja r√≥≈ºniczkowalna. W optymalizacji gradientowej potrzebujemy ciƒÖg≈Çych gradient√≥w, a norma L0 ich nie dostarcza. Nawet je≈õli spr√≥bujemy jƒÖ przybli≈ºyƒá np. u≈ºywajƒÖc funkcji sigmoidalnej (jest to sensowna propozycja na przybli≈ºenie normy L0, poniewa≈º w granicach $\\pm‚àû$ funkcja sigmoidalna przyjmuje warto≈õci 0 i 1, natomiast wysoki wsp√≥≈Çczynnik alfa u≈ºyty w kodzie zapewnia gwa≈Çtowny skok miƒôdzy 0 a 1), gradienty sƒÖ zerowe, co uniemo≈ºliwia skuteczne kierowanie punktami w stronƒô elipsy.\\\n",
        "**Wynik**: Trening nie postƒôpuje, bo optymalizator nie otrzymuje u≈ºytecznych informacji o tym, jak dostosowaƒá pozycje punkt√≥w.\\\n",
        "Wnioski te sƒÖ zgodne z animacjƒÖ ruchu punkt√≥w, na kt√≥rej widaƒá, ≈ºe wiƒôkszo≈õƒá punkt√≥w jest nieruchoma, niekt√≥re punkty nieznacznie siƒô przemieszczajƒÖ, jednak mimo to nie tworzƒÖ elipsy.\\\n",
        "Na wykresie straty widzimy, ≈ºe strata jest prawie stale r√≥wna 1, co jest zgodne z brakiem zbli≈ºania siƒô do kszta≈Çtu elipsy punkt√≥w przedstawionych w animacji."
      ],
      "metadata": {
        "id": "7V-lXvTjWhUV"
      }
    }
  ]
}