{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyu42duhtd00PbdP7JNVA0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaksta1/Uczenie_Maszynowe_2025/blob/main/Jakub_Kownacki_praca_domowa_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------\n",
        "# 1. Importowanie bibliotek\n",
        "---------------------------------"
      ],
      "metadata": {
        "id": "ZqmEufEwLMCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "plt.rcParams['animation.embed_limit'] = 50 #zwiÄ™kszenie limitu pamiÄ™ci do stworzenia animacji\n",
        "# Ustawienie ziarna dla powtarzalnoÅ›ci\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "0S6eQNomJm7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------\n",
        "#2. Ustawienia parametrÃ³w\n",
        "-------------------------------------------"
      ],
      "metadata": {
        "id": "ECALgDkOLbfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametry elipsy\n",
        "focus1 = torch.tensor([-2.0, 0.0])  # Pierwsze ognisko\n",
        "focus2 = torch.tensor([2.0, 0.0])   # Drugie ognisko\n",
        "constant_sum = 6.0                  # StaÅ‚a suma odlegÅ‚oÅ›ci\n",
        "\n",
        "# Inicjalizacja losowych punktÃ³w\n",
        "num_points = 100\n",
        "points = torch.rand((num_points, 2)) * 10 - 5  # RozkÅ‚ad jednostajny w [-5, 5]\n",
        "points.requires_grad = True"
      ],
      "metadata": {
        "id": "rV_KIIy5Lw7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------------------------------\n",
        "#3. Funkcje pomocnicze\n",
        "------------------------------------------------"
      ],
      "metadata": {
        "id": "6J-EKi9tLzJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja obliczajÄ…ca odlegÅ‚oÅ›ci\n",
        "def compute_distances(points, focus1, focus2):\n",
        "    dist1 = torch.norm(points - focus1, dim=1)\n",
        "    dist2 = torch.norm(points - focus2, dim=1)\n",
        "    return dist1, dist2\n",
        "\n",
        "def l0_approx_sigmoid(epsilon, delta, alpha=50):\n",
        "    \"\"\"\n",
        "    Aproksymacja normy L0 za pomocÄ… funkcji sigmoidalnej.\n",
        "    Parametry:\n",
        "        epsilon: tensor wartoÅ›ci bÅ‚Ä™dÃ³w\n",
        "        delta: prÃ³g, poniÅ¼ej ktÃ³rego bÅ‚Ä™dy sÄ… uznawane za zerowe\n",
        "        alpha: parametr kontrolujÄ…cy nachylenie funkcji sigmoidalnej, wiÄ™ksze wartoÅ›ci alpha sprawiajÄ…,\n",
        "        Å¼e aproksymacja staje siÄ™ bardziej \"skokowa\", zbliÅ¼ajÄ…c siÄ™ do idealnej normy L0\n",
        "        rÃ³Å¼niczkowalnoÅ›Ä‡: funkcja sigmoidalna jest rÃ³Å¼niczkowalna, zatem moÅ¼emy jej uÅ¼yÄ‡ do\n",
        "        obliczenia gradientu funkcji straty.\n",
        "    Zwraca:\n",
        "        aproksymowanÄ… wartoÅ›Ä‡ normy L0\n",
        "    \"\"\"\n",
        "    return 1 / (1 + torch.exp(-alpha * (torch.abs(epsilon) - delta)))\n",
        "\n",
        "# Funkcja treningowa z zapisem trajektorii i straty\n",
        "def train_with_animation(loss_type, num_epochs=1000, lr=0.1):\n",
        "    points = torch.rand((num_points, 2)) * 10 - 5\n",
        "    points.requires_grad = True\n",
        "    optimizer = torch.optim.Adam([points], lr=lr)\n",
        "    trajectories = []  # Lista do przechowywania poÅ‚oÅ¼enia punktÃ³w w kaÅ¼dej epoce\n",
        "    loss_history = []  # Lista do przechowywania wartoÅ›ci straty w kaÅ¼dej epoce\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        dist1, dist2 = compute_distances(points, focus1, focus2)\n",
        "        epsilon = dist1 + dist2 - constant_sum\n",
        "\n",
        "        if loss_type == \"l2\":\n",
        "            loss = torch.mean(epsilon ** 2)\n",
        "        elif loss_type == \"l1\":\n",
        "            loss = torch.mean(torch.abs(epsilon))\n",
        "        elif loss_type == \"linf\":\n",
        "            loss = torch.max(torch.abs(epsilon))\n",
        "        elif loss_type == \"l0\":\n",
        "            delta = 0.01\n",
        "            loss = torch.mean(l0_approx_sigmoid(epsilon, delta))  # UÅ¼yj aproksymacji sigmoidalnej\n",
        "        else:\n",
        "            raise ValueError(\"NieprawidÅ‚owy typ straty\")\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zapisz aktualne poÅ‚oÅ¼enia punktÃ³w i stratÄ™\n",
        "        trajectories.append(points.detach().clone().numpy())\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "    return trajectories, loss_history"
      ],
      "metadata": {
        "id": "-dyRgQ02MFNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------\n",
        "#4. Trening dla straty L1\n",
        "---------------------------------------------"
      ],
      "metadata": {
        "id": "mYMnk26mM3mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uruchom trening dla straty l1\n",
        "trajectories_l1, loss_history_l1 = train_with_animation(\"l1\", num_epochs=300)\n",
        "\n",
        "# Tworzenie animacji z dwoma subplotami\n",
        "fig_l1, (ax1_l1, ax2_l1) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Punkty\n",
        "ax1_l1.set_xlim(-6, 6)\n",
        "ax1_l1.set_ylim(-6, 6)\n",
        "scatter_l1 = ax1_l1.scatter([], [], label='Punkty')\n",
        "ax1_l1.scatter([focus1[0], focus2[0]], [focus1[1], focus2[1]], color='red', marker='x', s=100, label='Ogniska')\n",
        "ax1_l1.legend()\n",
        "ax1_l1.grid()\n",
        "ax1_l1.set_title('Ruch punktÃ³w dla straty L1')\n",
        "\n",
        "# Subplot 2: Wykres straty\n",
        "ax2_l1.set_xlim(0, len(loss_history_l1))\n",
        "ax2_l1.set_ylim(0, max(loss_history_l1) * 1.1)\n",
        "line_l1, = ax2_l1.plot([], [], color='blue')\n",
        "ax2_l1.set_xlabel('Epoka')\n",
        "ax2_l1.set_ylabel('Strata')\n",
        "ax2_l1.set_title('Przebieg funkcji straty L1')\n",
        "ax2_l1.grid()\n",
        "\n",
        "def update_l1(frame):\n",
        "    # Aktualizacja poÅ‚oÅ¼enia punktÃ³w\n",
        "    scatter_l1.set_offsets(trajectories_l1[frame])\n",
        "\n",
        "    # Aktualizacja wykresu straty\n",
        "    line_l1.set_data(range(frame + 1), loss_history_l1[:frame + 1])\n",
        "\n",
        "    return scatter_l1, line_l1\n",
        "\n",
        "ani_l1 = animation.FuncAnimation(fig_l1, update_l1, frames=len(trajectories_l1), interval=50, blit=True)\n",
        "print(\"Ostatnia wartoÅ›Ä‡ funkcji bÅ‚Ä™du L1:\", loss_history_l1[-1])\n",
        "\n",
        "# WyÅ›wietlenie animacji w notebooku\n",
        "HTML(ani_l1.to_jshtml())\n"
      ],
      "metadata": {
        "id": "p2WOMuFPDH5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dlaczego strata $L^1$ nie zbiega do zera nawet po narysowaniu elipsy?\n",
        "\n",
        "Norma L1 to $ğ¿_{\\text{ellipse}}^{(1)}=\\frac{1}{ğ‘}âˆ‘_{ğ‘–=1}^ğ‘âˆ£ğœ–_ğ‘–âˆ£$, czyli Å›rednia wartoÅ›Ä‡ bezwzglÄ™dna bÅ‚Ä™dÃ³w.\\\n",
        "Powodem nie zbiegania straty L1 do 0 jest to, Å¼e w przeciwieÅ„stwie do normy L2 (bÅ‚Ä™du kwadratowego), ktÃ³ra silnie karze nawet maÅ‚e odchylenia (gradient roÅ›nie z bÅ‚Ä™dem), norma L1 ma staÅ‚y gradient (Â±1 w zaleÅ¼noÅ›ci od znaku $ğœ–_ğ‘– $â€‹\n",
        " ). To sprawia, Å¼e maÅ‚e bÅ‚Ä™dy sÄ… sÅ‚abo penalizowane, wiÄ™c punkty mogÄ… byÄ‡ blisko elipsy, ale nie dokÅ‚adnie na niej. W zwiÄ…zku z tym optymalizacja moÅ¼e oscylowaÄ‡ lub zwolniÄ‡, gdy bÅ‚Ä™dy sÄ… maÅ‚e, co prowadzi do ustabilizowania wartoÅ›ci straty na poziomie powyÅ¼ej zera.\\\n",
        "**Wynik**: Strata nie zbiega do zera, bo L1 nie wymusza precyzyjnego dopasowania punktÃ³w do warunku.\\\n",
        "Wszystkie te wnioski sÄ… zgodne z powyÅ¼szÄ… animacjÄ…, na ktÃ³rej widaÄ‡, Å¼e dla odpowiednio duÅ¼ej liczby iteracji bÅ‚Ä…d utrzymuje siÄ™ na staÅ‚ej wartoÅ›ci okoÅ‚o 0.02 pomimo tego, Å¼e uzyskaliÅ›my elipsÄ™."
      ],
      "metadata": {
        "id": "h5jJqWVhM-W0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------------------------------------\n",
        "#5. Trening dla straty $L^{âˆ}$\n",
        "-----------------------------------------------"
      ],
      "metadata": {
        "id": "_S9Er7tvPp7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uruchom trening dla straty L_inf\n",
        "trajectories_linf, loss_history_linf = train_with_animation(\"linf\", num_epochs=800)\n",
        "\n",
        "# Tworzenie animacji z dwoma subplotami\n",
        "fig_linf, (ax1_linf, ax2_linf) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Punkty\n",
        "ax1_linf.set_xlim(-6, 6)\n",
        "ax1_linf.set_ylim(-6, 6)\n",
        "scatter_linf = ax1_linf.scatter([], [], label='Punkty')\n",
        "ax1_linf.scatter([focus1[0], focus2[0]], [focus1[1], focus2[1]], color='red', marker='x', s=100, label='Ogniska')\n",
        "ax1_linf.legend()\n",
        "ax1_linf.grid()\n",
        "ax1_linf.set_title('Ruch punktÃ³w dla straty L_inf')\n",
        "\n",
        "# Subplot 2: Wykres straty\n",
        "ax2_linf.set_xlim(0, len(loss_history_linf))\n",
        "ax2_linf.set_ylim(0, max(loss_history_linf) * 1.1)\n",
        "line_linf, = ax2_linf.plot([], [], color='blue')\n",
        "ax2_linf.set_xlabel('Epoka')\n",
        "ax2_linf.set_ylabel('Strata')\n",
        "ax2_linf.set_title('Przebieg funkcji straty L_inf')\n",
        "ax2_linf.grid()\n",
        "\n",
        "def update_linf(frame):\n",
        "    # Aktualizacja poÅ‚oÅ¼enia punktÃ³w\n",
        "    scatter_linf.set_offsets(trajectories_linf[frame])\n",
        "\n",
        "    # Aktualizacja wykresu straty\n",
        "    line_linf.set_data(range(frame + 1), loss_history_linf[:frame + 1])\n",
        "\n",
        "    return scatter_linf, line_linf\n",
        "\n",
        "ani_linf = animation.FuncAnimation(fig_linf, update_linf, frames=len(trajectories_linf), interval=50, blit=True)\n",
        "print(\"Ostatnia wartoÅ›Ä‡ funkcji bÅ‚Ä™du L_inf:\", loss_history_linf[-1])\n",
        "\n",
        "# WyÅ›wietlenie animacji w notebooku\n",
        "HTML(ani_linf.to_jshtml())\n"
      ],
      "metadata": {
        "id": "qv00aaZsELtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dlaczego trening trwa dÅ‚ugo i strata nie zbiega do zera?\n",
        "\n",
        "Norma $L_{\\text{inf}}$ to maksymalny bÅ‚Ä…d wÅ›rÃ³d wszystkich punktÃ³w.\\\n",
        "Zatem optymalizacja koncentruje siÄ™ wyÅ‚Ä…cznie na punkcie z najwiÄ™kszym bÅ‚Ä™dem, ignorujÄ…c pozostaÅ‚e, dopÃ³ki ten bÅ‚Ä…d nie zostanie zredukowany. To powoduje powolny postÄ™p, bo tylko jeden punkt (lub kilka) jest poprawianych w kaÅ¼dej iteracji. Istnieje teÅ¼ ryzyko przeÅ‚Ä…czanie siÄ™ miÄ™dzy punktami o najwiÄ™kszym bÅ‚Ä™dzie, co prowadzi do nieefektywnego ruchu w przestrzeni, a brak rÃ³wnoczesnej poprawy wszystkich punktÃ³w utrudnia peÅ‚ne dopasowanie do elipsy.\\\n",
        "**Wynik**: Trening jest wolny i czÄ™sto nie zbiega do zera, bo strategia \"najgorszego przypadku\" nie optymalizuje globalnie ukÅ‚adu punktÃ³w.\\\n",
        "Na powyÅ¼szej animacji ruchu punktÃ³w widaÄ‡, Å¼e na poczÄ…tku udaje siÄ™ uzyskaÄ‡ \"zarys\" elipsy, jednak w pewnym momencie algorytmowi ciÄ™Å¼ko wybraÄ‡ punkty i kierunek ich przesuniÄ™cia taki, aby zmniejszyÄ‡ bÅ‚Ä…d, co widaÄ‡ na animacji przebiegu funkcji straty."
      ],
      "metadata": {
        "id": "Q82YIViMU1XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------------------------------\n",
        "#6. Trening dla straty L0\n",
        "----------------------------------------------"
      ],
      "metadata": {
        "id": "uyNTbx7Oakcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uruchom trening dla straty l0\n",
        "trajectories_l0, loss_history_l0 = train_with_animation(\"l0\", num_epochs=300)\n",
        "\n",
        "# Tworzenie animacji z dwoma subplotami\n",
        "fig_l0, (ax1_l0, ax2_l0) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "# Subplot 1: Punkty\n",
        "ax1_l0.set_xlim(-6, 6)\n",
        "ax1_l0.set_ylim(-6, 6)\n",
        "scatter_l0 = ax1_l0.scatter([], [], label='Punkty')\n",
        "ax1_l0.scatter([focus1[0], focus2[0]], [focus1[1], focus2[1]], color='red', marker='x', s=100, label='Ogniska')\n",
        "ax1_l0.legend()\n",
        "ax1_l0.grid()\n",
        "ax1_l0.set_title('Ruch punktÃ³w dla straty L0')\n",
        "\n",
        "# Subplot 2: Wykres straty\n",
        "ax2_l0.set_xlim(0, len(loss_history_l0))\n",
        "ax2_l0.set_ylim(0, max(loss_history_l0) * 1.1 if loss_history_l0 else 1)\n",
        "line_l0, = ax2_l0.plot([], [], color='blue')\n",
        "ax2_l0.set_xlabel('Epoka')\n",
        "ax2_l0.set_ylabel('Strata')\n",
        "ax2_l0.set_title('Przebieg funkcji straty L0')\n",
        "ax2_l0.grid()\n",
        "\n",
        "def update_l0(frame):\n",
        "    # Aktualizacja poÅ‚oÅ¼enia punktÃ³w\n",
        "    scatter_l0.set_offsets(trajectories_l0[frame])\n",
        "\n",
        "    # Aktualizacja wykresu straty\n",
        "    line_l0.set_data(range(frame + 1), loss_history_l0[:frame + 1])\n",
        "\n",
        "    return scatter_l0, line_l0\n",
        "\n",
        "ani_l0 = animation.FuncAnimation(fig_l0, update_l0, frames=len(trajectories_l0), interval=50, blit=True)\n",
        "print(\"Ostatnia wartoÅ›Ä‡ funkcji bÅ‚Ä™du L0:\", loss_history_l0[-1])\n",
        "\n",
        "# WyÅ›wietlenie animacji w notebooku\n",
        "HTML(ani_l0.to_jshtml())"
      ],
      "metadata": {
        "id": "e8ISMSVfPJHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dlaczego trening nie postÄ™puje?\n",
        "Norma L0 jest zdefiniowana jako $L^{(0)}_{\\text{ellipse}}=\\frac{1}{N}âˆ‘_{i=1}^N\\mathbb{1}(Ïµ_i\\neq1)$.\\\n",
        "Norma L0 zlicza wiÄ™c stosunek liczby punktÃ³w, dla ktÃ³rych bÅ‚Ä…d $ğœ–_ğ‘–$ nie jest rÃ³wny zero do liczby wszystkich punktÃ³w.\\\n",
        "Trening nie postÄ™puje, poniewaÅ¼ indykator $\\mathbb{1}_(Ïµ_i\\neq1)$ jest funkcjÄ… skokowÄ… â€“ zmienia siÄ™ z 0 na 1 w sposÃ³b dyskretny, nie jest to zatem funkcja rÃ³Å¼niczkowalna. W optymalizacji gradientowej potrzebujemy ciÄ…gÅ‚ych gradientÃ³w, a norma L0 ich nie dostarcza. Nawet jeÅ›li sprÃ³bujemy jÄ… przybliÅ¼yÄ‡ np. uÅ¼ywajÄ…c funkcji sigmoidalnej, gradienty sÄ… zerowe, co uniemoÅ¼liwia skuteczne kierowanie punktami w stronÄ™ elipsy.\\\n",
        "**Wynik**: Trening nie postÄ™puje, bo optymalizator nie otrzymuje uÅ¼ytecznych informacji o tym, jak dostosowaÄ‡ pozycje punktÃ³w.\\\n",
        "Wnioski te sÄ… zgodne z animacjÄ… ruchu punktÃ³w, na ktÃ³rej widaÄ‡, Å¼e wiÄ™kszoÅ›Ä‡ punktÃ³w jest nieruchoma, niektÃ³re punkty nieznacznie siÄ™ przemieszczajÄ…, jednak mimo to nie tworzÄ… elipsy.\\\n",
        "Na wykresie straty widzimy, Å¼e strata jest prawie stale rÃ³wna 1, co jest zgodne z brakiem zbliÅ¼ania siÄ™ do ksztaÅ‚tu elipsy punktÃ³w przedstawionych w animacji."
      ],
      "metadata": {
        "id": "7V-lXvTjWhUV"
      }
    }
  ]
}